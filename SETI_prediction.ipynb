{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "# Restoring model and prediction\n",
    "\n",
    "\n",
    "--------------------\n",
    "In this notebook we load the model that we built before, and use it for prediction of signals.  \n",
    "__notice:__Make sure you have ran the `SETI_img_to-binary.ipynb` botebook, before running the following cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import SETI\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read your test data\n",
    "In the following cell, we read the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/SETI1_data/SETI_ds_64x128/train-images-idx3-ubyte.gz\n",
      "Extracting tmp/SETI1_data/SETI_ds_64x128/train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/SETI1_data/SETI_ds_64x128/test-images-idx3-ubyte.gz\n",
      "Extracting tmp/SETI1_data/SETI_ds_64x128/test-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 8192)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working directory\n",
    "dataset_name = 'SETI_ds_64x128'\n",
    "train_dir = \"tmp/SETI1_train/\"\n",
    "mydatafolder = \"tmp/SETI1_data/\"\n",
    "\n",
    "# check point directory\n",
    "chk_directory = train_dir + '/save1/' # it reads for the model built in the SETI_img_to-binary.ipynb\n",
    "checkpoint_path = chk_directory + 'model.ckpt'\n",
    "\n",
    "# Loading test set\n",
    "dataset = SETI.read_data_sets(mydatafolder + dataset_name, one_hot=True, validation_size=0)\n",
    "dataset.test.images.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the model\n",
    "First, we load meta graph and restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tmp/SETI1_train//save1/model.ckpt-300\n",
      "Model restored.\n",
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()    \n",
    "filename = \".\".join([tf.train.latest_checkpoint(chk_directory), \"meta\"])\n",
    "saver = tf.train.import_meta_graph(filename)\n",
    "saver.restore(sess,tf.train.latest_checkpoint(chk_directory))\n",
    "print(\"Model restored.\") \n",
    "print('Initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.get_default_graph()\n",
    "y_CNN = detection_graph.get_tensor_by_name(\"ReadoutLayer/softmax_linear:0\")\n",
    "x = detection_graph.get_tensor_by_name(\"x:0\")\n",
    "y_ = detection_graph.get_tensor_by_name(\"y_:0\")\n",
    "keep_prob = detection_graph.get_tensor_by_name(\"keep_prob:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Now we can simply use the test dataset to predict, we just have used 20 signals here for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = dataset.test.next_batch(20 ,shuffle=True)\n",
    "y_pred_lb = sess.run(tf.argmax(y_CNN,1), feed_dict={x: x_batch, y_: y_batch, keep_prob: 1.})\n",
    "y_pred = sess.run(y_CNN, feed_dict={x: x_batch, y_: y_batch, keep_prob: 1.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.80      0.89         5\n",
      "          1       0.44      1.00      0.62         4\n",
      "          2       0.67      0.29      0.40         7\n",
      "          3       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       0.77      0.70      0.69        20\n",
      "\n",
      "[[4 0 1 0]\n",
      " [0 4 0 0]\n",
      " [0 5 2 0]\n",
      " [0 0 0 4]]\n",
      "Classification accuracy: 0.700000\n",
      "Log Loss: 0.791993\n"
     ]
    }
   ],
   "source": [
    "y_truth_lb = np.argmax(y_batch,1) # ground truth\n",
    "print metrics.classification_report(y_true= y_truth_lb, y_pred= y_pred_lb)\n",
    "print metrics.confusion_matrix(y_true= y_truth_lb, y_pred= y_pred_lb)\n",
    "print(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true= y_truth_lb, y_pred= y_pred_lb) )\n",
    "print(\"Log Loss: %0.6f\" % metrics.log_loss(y_true= y_truth_lb, y_pred= y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deep Learning with TensorFlow](http://cocl.us/SETI-NIMBIX-ML0102EN) is a free course in __cognitiveclass.ia__ where you can learn TensorFlow and Deep Learning togetherwe.\n",
    "\n",
    "Also, running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a [free version of PowerAI](http://cocl.us/SETI-NIMBIX-PowerAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
