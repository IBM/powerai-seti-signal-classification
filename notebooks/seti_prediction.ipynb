{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "# Restoring model and prediction\n",
    "\n",
    "\n",
    "--------------------\n",
    "In this notebook, we load the model that we built before, and use it for prediction of signals.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import SETI\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read your test data\n",
    "In the following cell, we read the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory\n",
    "dataset_name = 'SETI_ds_64x128'\n",
    "train_dir = \"tmp/SETI1_train/\"\n",
    "mydatafolder = \"tmp/SETI1_data/\"\n",
    "\n",
    "# check point directory\n",
    "chk_directory = train_dir + '/save1/' # it reads for the model built in the SETI_img_to-binary.ipynb\n",
    "checkpoint_path = chk_directory + 'model.ckpt'\n",
    "\n",
    "# Loading test set\n",
    "dataset = SETI.read_data_sets(mydatafolder + dataset_name, one_hot=True, validation_size=0)\n",
    "dataset.test.images.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the model\n",
    "First, we load meta graph and restore weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()    \n",
    "filename = \".\".join([tf.train.latest_checkpoint(chk_directory), \"meta\"])\n",
    "saver = tf.train.import_meta_graph(filename)\n",
    "saver.restore(sess,tf.train.latest_checkpoint(chk_directory))\n",
    "print(\"Model restored.\") \n",
    "print('Initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.get_default_graph()\n",
    "y_CNN = detection_graph.get_tensor_by_name(\"ReadoutLayer/softmax_linear:0\")\n",
    "x = detection_graph.get_tensor_by_name(\"x:0\")\n",
    "y_ = detection_graph.get_tensor_by_name(\"y_:0\")\n",
    "keep_prob = detection_graph.get_tensor_by_name(\"keep_prob:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "Now we can simply use the test dataset to predict. We will use 20 signals here for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = dataset.test.next_batch(20 ,shuffle=True)\n",
    "y_pred_lb = sess.run(tf.argmax(y_CNN,1), feed_dict={x: x_batch, y_: y_batch, keep_prob: 1.})\n",
    "y_pred = sess.run(y_CNN, feed_dict={x: x_batch, y_: y_batch, keep_prob: 1.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truth_lb = np.argmax(y_batch,1) # ground truth\n",
    "print metrics.classification_report(y_true= y_truth_lb, y_pred= y_pred_lb)\n",
    "print metrics.confusion_matrix(y_true= y_truth_lb, y_pred= y_pred_lb)\n",
    "print(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true= y_truth_lb, y_pred= y_pred_lb) )\n",
    "print(\"Log Loss: %0.6f\" % metrics.log_loss(y_true= y_truth_lb, y_pred= y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deep Learning with TensorFlow](http://cocl.us/SETI-NIMBIX-ML0102EN) is a free course in __cognitiveclass.ia__ where you can learn TensorFlow and Deep Learning together.\n",
    "\n",
    "Also, running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a [free version of PowerAI](http://cocl.us/SETI-NIMBIX-PowerAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
